{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to Week 5 Day 1\n",
    "\n",
    "AutoGen AgentChat!\n",
    "\n",
    "This should look simple and familiar, because it has a lot in common with Crew and OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First concept: the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model which is similar to concepts like LLm its like a wrapper around calling a large language model\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eample run local model with ollama\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "ollamamodel_client = OllamaChatCompletionClient(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second concept: The Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different concept from Autogen agent chat messages\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "message = TextMessage(content=\"I'd like to go to London\", source=\"user\") # 'user' refers to  'me'\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third concept: The Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "# most fundamental class working within AUtogen agent chat\n",
    "agent = AssistantAgent(\n",
    "    name=\"airline_agent\",\n",
    "    model_client=model_client, # underlying LLM\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers.\", # similar to instructions in OpenAI system messages \n",
    "    model_client_stream=True # is how we say that we want to stream back the results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together with on_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the thing that brings it all together\n",
    "# that is what we call on an agent to pass in a bunch of messages, put the messages in a list even if its just one message\n",
    "# also have to pass in a cancellation token, which is how it knows when the messages are finished.\n",
    "# async as its a couroutine so have to await it\n",
    "from autogen_core import CancellationToken\n",
    "response = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a local database of ticket prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Delete existing database file if it exists\n",
    "if os.path.exists(\"tickets.db\"):\n",
    "    os.remove(\"tickets.db\")\n",
    "\n",
    "# Create the database and the table\n",
    "conn = sqlite3.connect(\"tickets.db\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"CREATE TABLE cities (city_name TEXT PRIMARY KEY, round_trip_price REAL)\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate our database\n",
    "def save_city_price(city_name, round_trip_price):\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"REPLACE INTO cities (city_name, round_trip_price) VALUES (?, ?)\", (city_name.lower(), round_trip_price))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Some cities!\n",
    "save_city_price(\"London\", 299)\n",
    "save_city_price(\"Paris\", 399)\n",
    "save_city_price(\"Rome\", 499)\n",
    "save_city_price(\"Madrid\", 550)\n",
    "save_city_price(\"Barcelona\", 580)\n",
    "save_city_price(\"Berlin\", 525)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get price for a city\n",
    "def get_city_price(city_name: str) -> float | None:\n",
    "    # didn't have any kind of decorator or anything.\n",
    "    # In OpenAI agemts SDK we put in a decotatror, in Landgraph we  wrap it in a 'tool'\n",
    "    # Did not have to do anything like that, really lightweight\n",
    "    # And it's because, of course, they've just got a little bit of extra stuff in the abstraction code\n",
    "    # that sees this as a Python function.\n",
    "    # It uses this comment to figure out the description of the tool.\n",
    "    # So it just does a bit of that for you.\n",
    "    # It makes life a tiny bit easier.\n",
    "    \"\"\" Get the roundtrip ticket price to travel to the city \"\"\"\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT round_trip_price FROM cities WHERE city_name = ?\", (city_name.lower(),))\n",
    "    result = c.fetchone()\n",
    "    conn.close()\n",
    "    return result[0] if result else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_city_price(\"Rome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "smart_agent = AssistantAgent(\n",
    "    name=\"smart_airline_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers, including the price of a roundtrip ticket.\",\n",
    "    model_client_stream=True,\n",
    "    tools=[get_city_price], # pass in the tooll functions\n",
    "    # which is a way of indicating that we don't just want it to return the tool results.\n",
    "    # we do want it to be able to take that and continue processing even after the tool has returned.\n",
    "    # Rare to want it false, so should always ssume that  will be your default\n",
    "    reflect_on_tool_use=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await smart_agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "# Um, and then just just for the for fun, I'm going to print the inner messages.\n",
    "# I mentioned that the message construct isn't just for the human to the agent.\n",
    "# It's also for what's going on between agents and inside the agent.\n",
    "# So we can see that by printing its inner messages.\n",
    "for inner_message in response.inner_messages:\n",
    "    print(inner_message.content)\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
